{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_kFamuyLuCds"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.ensemble import AdaBoostClassifier  # Import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load a CSV file and return a pandas DataFrame.\"\"\"\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Preprocess the DataFrame by selecting relevant features and handling missing values.\"\"\"\n",
        "    # Select relevant feature columns\n",
        "    feature_cols = [\n",
        "        'acc_X', 'acc_Y', 'acc_Z',\n",
        "        'mag_X', 'mag_Y', 'mag_Z',\n",
        "        'gyro_X', 'gyro_Y', 'gyro_Z'\n",
        "    ]\n",
        "    selected_data = df[feature_cols]\n",
        "\n",
        "    # Handle missing values (fill with zeros)\n",
        "    selected_data = selected_data.fillna(0)\n",
        "\n",
        "    # Extract the target label column\n",
        "    labels = df['activity']\n",
        "\n",
        "    return selected_data, labels\n"
      ],
      "metadata": {
        "id": "KtOPrlmxuMZ4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Normalization\n",
        "def normalize_data(data):\n",
        "    \"\"\"Normalize the data using MinMaxScaler.\"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
        "    return normalized_data\n",
        "\n",
        "# Feature extraction\n",
        "def extract_features(window):\n",
        "    \"\"\"Extract statistical features from a window of data.\"\"\"\n",
        "    features = {}\n",
        "    for col in window.columns:\n",
        "        if len(window[col].unique()) > 1:  # Avoid constant columns\n",
        "            features[f'{col}_mean'] = window[col].mean()\n",
        "            features[f'{col}_std'] = window[col].std()\n",
        "            features[f'{col}_min'] = window[col].min()\n",
        "            features[f'{col}_max'] = window[col].max()\n",
        "        else:\n",
        "            # For constant columns\n",
        "            features[f'{col}_mean'] = window[col].mean()\n",
        "            features[f'{col}_std'] = 0\n",
        "            features[f'{col}_min'] = window[col].min()\n",
        "            features[f'{col}_max'] = window[col].max()\n",
        "    return features"
      ],
      "metadata": {
        "id": "A6AR5ZD0uVEp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_dataset(data, labels, window_size=50, step_size=25):\n",
        "    \"\"\"Create a dataset of features and corresponding labels from sliding windows.\"\"\"\n",
        "    X, y = [], []\n",
        "    for start in range(0, len(data) - window_size, step_size):\n",
        "        end = start + window_size\n",
        "        window = data.iloc[start:end]\n",
        "        label_window = labels.iloc[start:end]\n",
        "\n",
        "        # Extract features from the window\n",
        "        features = extract_features(window)\n",
        "        X.append(features)\n",
        "\n",
        "        # Assign the most frequent label in the window as the target label\n",
        "        label = label_window.mode().iloc[0]  # Most frequent label\n",
        "        y.append(label)\n",
        "\n",
        "    # Convert to DataFrame and Series\n",
        "    X = pd.DataFrame(X)\n",
        "    y = pd.Series(y)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "vZ-CCEFpunJy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training with AdaBoost\n",
        "def train_model(X, y):\n",
        "    \"\"\"Train an AdaBoost model.\"\"\"\n",
        "    # Encode categorical labels into numerical format\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize and train the AdaBoost model\n",
        "    clf = AdaBoostClassifier(n_estimators=100, random_state=42)  # Use AdaBoostClassifier\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "    return clf, label_encoder"
      ],
      "metadata": {
        "id": "hWsMuzDGurK1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Balancing Data using SMOTE\n",
        "def balance_data(X, y):\n",
        "    \"\"\"Balance the dataset using SMOTE.\"\"\"\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "    return X_balanced, y_balanced"
      ],
      "metadata": {
        "id": "k0alcCm6uwTE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "def save_model(model, label_encoder, output_path):\n",
        "    \"\"\"Save the trained model and label encoder to files.\"\"\"\n",
        "    joblib.dump(model, output_path)\n",
        "    joblib.dump(label_encoder, output_path.replace('.pkl', '_label_encoder.pkl'))\n",
        "    print(f\"Model saved as '{output_path}'\")\n",
        "    print(f\"Label encoder saved as '{output_path.replace('.pkl', '_label_encoder.pkl')}'\")\n"
      ],
      "metadata": {
        "id": "Zz3qPNSluwdp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main workflow\n",
        "def main(file_path):\n",
        "    # Load and preprocess data\n",
        "    print(\"Loading data...\")\n",
        "    df = load_data(file_path)\n",
        "    print(\"Data loaded successfully.\")\n",
        "\n",
        "    # Display unique activity labels\n",
        "    unique_activities = df['activity'].unique()\n",
        "    print(\"Unique activity labels:\", unique_activities)\n",
        "\n",
        "    data, labels = preprocess_data(df)\n",
        "    print(\"Data preprocessed successfully.\")\n",
        "\n",
        "    # Normalize data\n",
        "    print(\"Normalizing data...\")\n",
        "    data_normalized = normalize_data(data)\n",
        "    print(\"Data normalized successfully.\")\n",
        "\n",
        "    # Balance data\n",
        "    print(\"Balancing data using SMOTE...\")\n",
        "    X_balanced, y_balanced = balance_data(data_normalized, labels)\n",
        "    print(\"Data balanced successfully.\")\n",
        "\n",
        "    # Extract features and labels\n",
        "    print(\"Extracting features...\")\n",
        "    X, y = create_feature_dataset(X_balanced, y_balanced)\n",
        "    print(\"Feature extraction completed.\")\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Training the model...\")\n",
        "    model_adaboost, label_encoder = train_model(X, y)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(model_adaboost, label_encoder, 'movement_detection_adaboost_model.pkl')\n",
        "\n",
        "    return model_adaboost, label_encoder\n",
        "\n"
      ],
      "metadata": {
        "id": "keW9V6mku3PO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main workflow\n",
        "main('/content/dataset_tot1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDM_qSuju3XF",
        "outputId": "b68d0d7f-91ab-49ac-87e0-9d62ea301bdb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data loaded successfully.\n",
            "Unique activity labels: ['downstairs' 'running' 'standing' 'upstairs' 'walking']\n",
            "Data preprocessed successfully.\n",
            "Normalizing data...\n",
            "Data normalized successfully.\n",
            "Balancing data using SMOTE...\n",
            "Data balanced successfully.\n",
            "Extracting features...\n",
            "Feature extraction completed.\n",
            "Training the model...\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  downstairs       0.93      0.85      0.89      3785\n",
            "     running       0.95      0.89      0.92      3614\n",
            "    standing       0.95      0.94      0.94      3722\n",
            "    upstairs       0.92      0.82      0.87      3677\n",
            "     walking       0.71      0.90      0.79      3780\n",
            "\n",
            "    accuracy                           0.88     18578\n",
            "   macro avg       0.89      0.88      0.88     18578\n",
            "weighted avg       0.89      0.88      0.88     18578\n",
            "\n",
            "Model saved as 'movement_detection_adaboost_model.pkl'\n",
            "Label encoder saved as 'movement_detection_adaboost_model_label_encoder.pkl'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(AdaBoostClassifier(n_estimators=100, random_state=42), LabelEncoder())"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O_R_0T9WurXL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}